{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8be61930-b2ff-43d1-b602-2da7ec8f448a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\n",
    "  \"fs.azure.account.key.snowflakesa2.blob.core.windows.net\",\n",
    "  \"WbpRmcAjD57jy6vBIvB+wdv5rt9c5Nkb6BhUWPwySH90OhXvUxHvfQNTe8chnaWemX2Qo3RR37OT+AStgVvYWg==\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "408925a4-6fbc-42fc-9693-6768fddff084",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c73514b-5f68-48ea-8805-160ca2baa00a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"event_id\", StringType(), True),\n",
    "    StructField(\"event_time\", StringType(), True),\n",
    "    StructField(\"service_name\", StringType(), True),\n",
    "    StructField(\"log_level\", StringType(), True),\n",
    "    StructField(\"user_id\", StringType(), True),\n",
    "    StructField(\"api_endpoint\", StringType(), True),\n",
    "    StructField(\"response_time_ms\", IntegerType(), True),\n",
    "    StructField(\"error_message\", StringType(), True),\n",
    "    StructField(\"region\", StringType(), True),\n",
    "    StructField(\"_corrupt_record\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5b5bf3f-c0d9-4e1a-9977-bdef295fa83a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-------------+---------+-------+--------------+----------------+-------------+------+---------------+\n|event_id|event_time          |service_name |log_level|user_id|api_endpoint  |response_time_ms|error_message|region|_corrupt_record|\n+--------+--------------------+-------------+---------+-------+--------------+----------------+-------------+------+---------------+\n|evt_101 |2025-09-10T10:15:30Z|order-service|ERROR    |U1001  |/api/v1/orders|850             |Timeout      |IN    |NULL           |\n+--------+--------------------+-------------+---------+-------+--------------+----------------+-------------+------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_raw = spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"multiline\", \"true\") \\\n",
    "    .json(\"wasbs://logs@snowflakesa2.blob.core.windows.net/app_logs.json\")\n",
    "df_raw.count()\n",
    "df_raw.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48be5c9c-0df0-4cf2-88e0-cf523f586830",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, to_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9528f539-90ee-4f36-81dd-889cb460935d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------+---------+-------+--------------+----------------+-------------+------+----------+\n|EVENT_ID|         EVENT_TIME| SERVICE_NAME|LOG_LEVEL|USER_ID|  API_ENDPOINT|RESPONSE_TIME_MS|ERROR_MESSAGE|REGION|ERROR_FLAG|\n+--------+-------------------+-------------+---------+-------+--------------+----------------+-------------+------+----------+\n| evt_101|2025-09-10 10:15:30|order-service|    ERROR|  U1001|/api/v1/orders|             850|      Timeout|    IN|         Y|\n+--------+-------------------+-------------+---------+-------+--------------+----------------+-------------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df_clean = df_raw.select(\n",
    "    col(\"event_id\").alias(\"EVENT_ID\"),\n",
    "    to_timestamp(col(\"event_time\")).alias(\"EVENT_TIME\"),\n",
    "    col(\"service_name\").alias(\"SERVICE_NAME\"),\n",
    "    col(\"log_level\").alias(\"LOG_LEVEL\"),\n",
    "    col(\"user_id\").alias(\"USER_ID\"),\n",
    "    col(\"api_endpoint\").alias(\"API_ENDPOINT\"),\n",
    "    col(\"response_time_ms\").cast(\"int\").alias(\"RESPONSE_TIME_MS\"),\n",
    "    col(\"error_message\").alias(\"ERROR_MESSAGE\"),\n",
    "    col(\"region\").alias(\"REGION\"),\n",
    "    when(col(\"log_level\") == \"ERROR\", \"Y\").otherwise(\"N\").alias(\"ERROR_FLAG\")\n",
    ")\n",
    "\n",
    "df_clean.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3b77829-ab46-47b5-bed4-8c8b1b565df0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_raw.write.mode(\"overwrite\").format(\"delta\").save(\"/tmp/app_logs_delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc20894d-9d10-453d-a681-6f82689e9ad6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snowflake-snowpark-python\n  Using cached snowflake_snowpark_python-1.44.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: setuptools>=40.6.0 in /usr/local/lib/python3.12/dist-packages (from snowflake-snowpark-python) (74.0.0)\nRequirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (from snowflake-snowpark-python) (0.45.1)\nCollecting snowflake-connector-python<5.0.0,>=3.17.0 (from snowflake-snowpark-python)\n  Using cached snowflake_connector_python-4.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (78 kB)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.1.0 in /databricks/python3/lib/python3.12/site-packages (from snowflake-snowpark-python) (4.12.2)\nRequirement already satisfied: pyyaml in /databricks/python3/lib/python3.12/site-packages (from snowflake-snowpark-python) (6.0.2)\nRequirement already satisfied: cloudpickle!=2.1.0,!=2.2.0,<=3.1.1,>=1.6.0 in /databricks/python3/lib/python3.12/site-packages (from snowflake-snowpark-python) (3.0.0)\nRequirement already satisfied: protobuf<6.34,>=3.20 in /databricks/python3/lib/python3.12/site-packages (from snowflake-snowpark-python) (5.29.4)\nRequirement already satisfied: python-dateutil in /databricks/python3/lib/python3.12/site-packages (from snowflake-snowpark-python) (2.9.0.post0)\nCollecting tzlocal (from snowflake-snowpark-python)\n  Using cached tzlocal-5.3.1-py3-none-any.whl.metadata (7.6 kB)\nCollecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python)\n  Using cached asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\nCollecting cryptography>=44.0.1 (from snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python)\n  Using cached cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\nRequirement already satisfied: pyOpenSSL<26.0.0,>=24.0.0 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python) (24.2.1)\nRequirement already satisfied: pyjwt<3.0.0,>=2.10.1 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python) (2.10.1)\nRequirement already satisfied: pytz in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python) (2024.1)\nCollecting requests<3.0.0,>=2.32.4 (from snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python)\n  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python) (24.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python) (3.3.2)\nRequirement already satisfied: idna<4,>=3.7 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python) (3.7)\nRequirement already satisfied: certifi>=2024.7.4 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python) (2025.1.31)\nRequirement already satisfied: filelock<4,>=3.5 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python) (3.13.1)\nRequirement already satisfied: sortedcontainers>=2.4.0 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python) (2.4.0)\nRequirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python) (3.10.0)\nCollecting tomlkit (from snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python)\n  Using cached tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: boto3>=1.24 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python) (1.36.2)\nRequirement already satisfied: botocore>=1.24 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python) (1.36.3)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil->snowflake-snowpark-python) (1.16.0)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /databricks/python3/lib/python3.12/site-packages (from boto3>=1.24->snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python) (1.0.1)\nRequirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /databricks/python3/lib/python3.12/site-packages (from boto3>=1.24->snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python) (0.11.3)\nRequirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /databricks/python3/lib/python3.12/site-packages (from botocore>=1.24->snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python) (2.3.0)\nCollecting cffi>=2.0.0 (from cryptography>=44.0.1->snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python)\n  Using cached cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\nINFO: pip is looking at multiple versions of pyopenssl to determine which version is compatible with other requirements. This could take a while.\nCollecting pyOpenSSL<26.0.0,>=24.0.0 (from snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python)\n  Using cached pyopenssl-25.3.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=44.0.1->snowflake-connector-python<5.0.0,>=3.17.0->snowflake-snowpark-python) (2.21)\nUsing cached snowflake_snowpark_python-1.44.0-py3-none-any.whl (1.8 MB)\nUsing cached snowflake_connector_python-4.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\nUsing cached tzlocal-5.3.1-py3-none-any.whl (18 kB)\nUsing cached asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\nUsing cached cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\nUsing cached pyopenssl-25.3.0-py3-none-any.whl (57 kB)\nUsing cached requests-2.32.5-py3-none-any.whl (64 kB)\nUsing cached tomlkit-0.13.3-py3-none-any.whl (38 kB)\nUsing cached cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (219 kB)\nInstalling collected packages: asn1crypto, tzlocal, tomlkit, requests, cffi, cryptography, pyOpenSSL, snowflake-connector-python, snowflake-snowpark-python\n  Attempting uninstall: requests\n    Found existing installation: requests 2.32.3\n    Not uninstalling requests at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-6c574990-14a2-45aa-99f1-789db9963015\n    Can't uninstall 'requests'. No files were found to uninstall.\n  Attempting uninstall: cffi\n    Found existing installation: cffi 1.17.1\n    Not uninstalling cffi at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-6c574990-14a2-45aa-99f1-789db9963015\n    Can't uninstall 'cffi'. No files were found to uninstall.\n  Attempting uninstall: cryptography\n    Found existing installation: cryptography 43.0.3\n    Not uninstalling cryptography at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-6c574990-14a2-45aa-99f1-789db9963015\n    Can't uninstall 'cryptography'. No files were found to uninstall.\n  Attempting uninstall: pyOpenSSL\n    Found existing installation: pyOpenSSL 24.2.1\n    Not uninstalling pyopenssl at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-6c574990-14a2-45aa-99f1-789db9963015\n    Can't uninstall 'pyOpenSSL'. No files were found to uninstall.\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\noci 2.160.2 requires cryptography<46.0.0,>=3.2.1, but you have cryptography 46.0.3 which is incompatible.\noci 2.160.2 requires pyOpenSSL<25.0.0,>=17.5.0, but you have pyopenssl 25.3.0 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0mSuccessfully installed asn1crypto-1.5.1 cffi-2.0.0 cryptography-46.0.3 pyOpenSSL-25.3.0 requests-2.32.5 snowflake-connector-python-4.1.1 snowflake-snowpark-python-1.44.0 tomlkit-0.13.3 tzlocal-5.3.1\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install snowflake-snowpark-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5faf5c01-b81f-4691-8483-099ec6b96556",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea8bb23d-04e0-45fb-8800-72973605f4e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "connection_parameters = {\n",
    "  \"account\": \"QYQSSEQ-UT92541\",\n",
    "  \"user\": \"BARATH46\",\n",
    "  \"password\": \"Rbarathraj@2711\",\n",
    "  \"role\": \"SYSADMIN\",\n",
    "  \"warehouse\": \"LOGS_WH\",\n",
    "  \"database\": \"LOG_ANALYTICS_DB\",\n",
    "  \"schema\": \"PUBLIC\"\n",
    "}\n",
    "\n",
    "session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1797a3f8-da54-46bb-8659-68bb6d14e2db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf = df_clean.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80bf5609-80dc-4f7a-bfc3-59098c462c8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<snowflake.snowpark.table.Table at 0x7f5da97b4fb0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.write_pandas(\n",
    "    pdf,\n",
    "    table_name=\"APPLICATION_LOGS\",\n",
    "    overwrite=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "app_log_analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}